{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Balancing Classes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution\n",
    "Up until this point, I had mostly just been working with 5% of my total data. After playing around with Tableau for a while, I came up with some plots similar to these:  \n",
    "<img src='pics/bars.svg'> <img src='pics/pie.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly I need to correct this somehow. Up until now, I had been mostly seeing what the models could do with what I gave them, but moving forward I wanted something a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SciServer import SkyQuery, SciDrive\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model_processes as mp\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.utils import check_sampling_strategy\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load table containing all 500k+ rows of my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_source = 'webuser.AllStars'\n",
    "database = 'MyDB'\n",
    "\n",
    "df = SkyQuery.getTable(table_source, datasetName=database)\n",
    "df = df.set_index('#SPECOBJID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "#output: (524354, 341)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = mp.grouped_frame(df)\n",
    "X, y = df_grouped.iloc[:,1:].sort_index(axis=1), df_grouped.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=25, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Undersampling\n",
    "I started with just randomly undersampling all classes except the minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sampled, y_sampled = RandomUnderSampler(random_state=42).fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':'multi:softmax', 'tree_method':'hist', 'n_estimators':500,\n",
    "          'num_class':9, 'seed':42}\n",
    "\n",
    "xbg_model = XGBClassifier(params).fit(X_sampled, y_sampled)\n",
    "y_pred = xbg_model.predict(X_test)\n",
    "\n",
    "cf = (confusion_matrix(y_true=y_test, y_pred=y_pred, normalize='true') * 100).astype(int)\n",
    "ba = balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: ba = 0.8432023516694044 <- already a jump of around 0.07!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(list(y_test.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mp.print_confusion_matrices({'XGBoost':cf.astype(int)}, class_names, figsz=(8,5))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pics/xgb_sampled.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix also looks significantly better for the minority classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Random Forest\n",
    "Next I tried out imblearn's Balanced Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "balanced_model = BalancedRandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred_rf = model.predict(X_test)\n",
    "cf_rf = (confusion_matrix(y_true=y_test, y_pred=y_pred_rf, normalize='true') * 100).astype(int)\n",
    "ba_rf = balanced_accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_model.fit(X_train, y_train)\n",
    "y_pred_brf = balanced_model.predict(X_test)\n",
    "cf_brf = (confusion_matrix(y_true=y_test, y_pred=y_pred_brf, normalize='true') * 100).astype(int)\n",
    "ba_brf = balanced_accuracy_score(y_test, y_pred_brf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced accuracy scores:  \n",
    "Undersampling from above: 0.8432023516694044  \n",
    "Random Forest: 0.7664527226475953  \n",
    "Balanced Random Forest: 0.8412801777174002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = mp.print_confusion_matrices({'Random Forest':cf_rf, \n",
    "                                  'Balanced Random Forest':cf_brf,\n",
    "                                  'XGBoost Random Undersample':cf}, \n",
    "                                  class_names, figsz=(8,5))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pics/brf_vs_rf_vs_under.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, looks like both are a significant improvement, although balanced random forest took ages to train, so undersampling is winning thus far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Combined Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = check_sampling_strategy('auto', y_train, 'over-sampling')\n",
    "under = check_sampling_strategy('auto', y_train, 'under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "over:  \n",
    "[('A', 124118), \n",
    "             ('CV', 168574), \n",
    "             ('CarbonWD', 161148), \n",
    "             ('G', 138178), \n",
    "             ('K', 85275), \n",
    "             ('LT', 167068), \n",
    "             ('M', 100463), \n",
    "             ('OB', 168474)]  \n",
    "under:  \n",
    "[('A', 1735), \n",
    "             ('CarbonWD', 1735), \n",
    "             ('F', 1735), \n",
    "             ('G', 1735), \n",
    "             ('K', 1735), \n",
    "             ('LT', 1735), \n",
    "             ('M', 1735), \n",
    "             ('OB', 1735)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so definitely don't want to try oversampling - not only would I end up with stupid amounts of data, for some classes I'd have around 10 times as much synthetic data as real data.  \n",
    "But undersampling is giving me a pretty small sample size to work with: about 3% of my original data.  \n",
    "So let's try something in between:  \n",
    "- Under-sample: M, F, A, K, G\n",
    "- Over-sample: CarbonWD, LT, OB, CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under = {'M':10000, 'F':10000, 'A':10000, 'K':10000, 'G':10000}\n",
    "over = {'CarbonWD':10000, 'LT':10000, 'OB':10000, 'CV':10000}\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=under, random_state=42)\n",
    "oversample_rand = RandomOverSampler(sampling_strategy=over, random_state=42)\n",
    "oversample_smote = SMOTE(sampling_strategy=over, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under, y_under = undersample.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to try out both random over sampling and SMOTE, and see which does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over_rand, y_over_rand = oversample_rand.fit_sample(X_under, y_under)\n",
    "X_over_smote, y_over_smote = oversample_smote.fit_sample(X_under, y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg_model_rand = XGBClassifier(params).fit(X_over_rand, y_over_rand)\n",
    "y_pred_rand = xbg_model_rand.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbg_model_smote = XGBClassifier(params).fit(X_over_smote, y_over_smote)\n",
    "y_pred_smote = xbg_model_smote.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_rand = (confusion_matrix(y_true=y_test, y_pred=y_pred_rand, normalize='true') * 100).astype(int)\n",
    "cf_smote = (confusion_matrix(y_true=y_test, y_pred=y_pred_smote, normalize='true') * 100).astype(int)\n",
    "ba_rand = balanced_accuracy_score(y_test, y_pred_rand)\n",
    "ba_smote = balanced_accuracy_score(y_test, y_pred_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced Accuracy Scores:\n",
    "\n",
    "Balanced Random Forest: 0.8413  \n",
    "XGBoost Random Undersample: 0.8432  \n",
    "XGBoost Under/Oversample Random: 0.8454  \n",
    "XGBoost Under/Oversample Smote: 0.8446  \n",
    "<img src='pics/resample_all.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these methods seem pretty even from these results! I was struggling to decide, so in a moment of insanity, I ran cross_val_score on all these models (it took sooooo long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cross_val_score(xbg_model, X_sampled, y_sampled, scoring='balanced_accuracy')\n",
    "c_brf = cross_val_score(balanced_model, X_train, y_train, scoring='balanced_accuracy')\n",
    "c_rand = cross_val_score(XGBClassifier(params), X_over_rand, y_over_rand, scoring='balanced_accuracy')\n",
    "c_smote = cross_val_score(XGBClassifier(params), X_over_smote, y_over_smote, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Val Scores:\n",
    "\n",
    "Balanced Random Forest: [0.8452 0.8402 0.8393 0.8458 0.8402]  \n",
    "XGBoost Random Undersample: [0.8473 0.845  0.8444 0.8405 0.8479]  \n",
    "XGBoost Under/Oversample Random: [0.9348 0.937  0.9397 0.9346 0.9408]  \n",
    "XGBoost Under/Oversample Smote: [0.8752 0.9219 0.9301 0.9253 0.9296]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so I realize that this score isn't as reflective of model performance since it's testing on data that been altered, but! Either it means something that the Under/Oversample Random model did so well or it doesn't, and if it doesn't, by the other metrics all of these were about the same, so let's go with this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = X_over_rand.merge(y_over_rand, left_index=True, right_index=True)#best performing sampling method\n",
    "df_sampled = df_sampled[['SUBCLASS', *df_sampled.columns[:-1]]]\n",
    "df_test = X_test.merge(y_test, left_index=True, right_index=True)#best performing sampling method\n",
    "df_test = df_test[['SUBCLASS', *df_test.columns[:-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    SciDrive.upload(path='metis_project_3/AllStarsSampled.csv', data = df_sampled.to_csv())\n",
    "    SciDrive.upload(path='metis_project_3/AllStarsSampledTest.csv', data = df_test.to_csv())\n",
    "except:\n",
    "    sp.login()\n",
    "    SciDrive.upload(path='metis_project_3/AllStarsSampled.csv', data = df_sampled.to_csv())\n",
    "    SciDrive.upload(path='metis_project_3/AllStarsSampledTest.csv', data = df_test.to_csv())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
